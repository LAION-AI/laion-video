# video-clip

Build video models


https://github.com/LAION-AI/project-menu/issues/22
https://docs.google.com/document/d/1WGGRzPAJw1uwUEuNgWlOYPg3yZJetyvsIQLtJ8nV8FQ/edit?usp=sharing


## Datasets
HowTo100M: Learning a Text-Video Embedding by Watching Hundred Million Narrated Video Clips


## Models

Video Swin Transformer

Swin Transformer

An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale

TokenLearner: What Can 8 Learned Tokens Do for Images and Videos?

Masked Feature Prediction for Self-Supervised Visual Pre-training

BEIT: BERT Pre-Training of Image Transformers

Multiview Transformers for Video Recognition

SiT: Self-supervised vIsion Transformer

Unsupervised Pre-Training of Image Features on Non-Curated Data

Co-training Transformer with Videos and Images Improves Action Recognition

Emerging Properties in Self-Supervised Vision Transformers

Florence: A New Foundation Model for Computer Vision

Swin Transformer V2: Scaling Up Capacity and Resolution

Neural Machine Translation by Jointly Learning to Align and Translate

MERLOT Reserve: Neural Script Knowledge through Vision and Language and Sound

MeMViT: Memory-Augmented Multiscale Vision Transformer
for Efficient Long-Term Video Recognition (longer temporal captioning for >5s video?)

Frozen in Time: A Joint Video and Image Encoder for End-to-End Retrieval 

### contrastive


https://arxiv.org/abs/2203.12602
https://github.com/MCG-NJU/VideoMAE

A Large-Scale Study on Unsupervised Spatiotemporal Representation Learning (not multimodal but maybe useful)

FitCLIP: Refining Large-Scale Pretrained Image-Text Models for Zero-Shot Video Understanding Tasks
(untested - repo link in paper doesnt work.)

CLIP2Video: Mastering Video-Text Retrieval via Image CLIP
https://github.com/CryhanFang/CLIP2Video (untested repo)


* (video, text)
* (video, image)

### Generative


video -> text 

text -> video 

video -> image 

image -> video 
